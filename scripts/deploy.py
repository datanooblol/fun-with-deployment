#!/usr/bin/env python3\n\"\"\"\nDeployment script for DS Pipeline\nBuilds Docker image, pushes to ECR, and deploys CDK stack\n\"\"\"\nimport subprocess\nimport boto3\nimport json\nimport sys\nimport argparse\nfrom pathlib import Path\n\ndef get_account_region():\n    \"\"\"Get AWS account and region\"\"\"\n    try:\n        sts = boto3.client('sts')\n        account = sts.get_caller_identity()['Account']\n        region = boto3.Session().region_name or 'us-east-1'\n        return account, region\n    except Exception as e:\n        print(f\"Error getting AWS account info: {e}\")\n        sys.exit(1)\n\ndef build_and_push_image(environment=\"dev\"):\n    \"\"\"Build and push Docker image to ECR\"\"\"\n    account, region = get_account_region()\n    \n    # ECR repository URI\n    ecr_uri = f\"{account}.dkr.ecr.{region}.amazonaws.com/ds-preprocessing:latest\"\n    \n    print(f\"Building Docker image for {environment} environment...\")\n    try:\n        subprocess.run([\n            \"docker\", \"build\", \n            \"-t\", \"ds-preprocessing\",\n            \"-f\", \"container_solution/preprocessing/Dockerfile\",\n            \"container_solution/preprocessing/\"\n        ], check=True)\n    except subprocess.CalledProcessError:\n        print(\"Docker build failed\")\n        sys.exit(1)\n    \n    print(\"Logging into ECR...\")\n    try:\n        # Get ECR login token\n        ecr = boto3.client('ecr', region_name=region)\n        token_response = ecr.get_authorization_token()\n        token = token_response['authorizationData'][0]['authorizationToken']\n        \n        # Decode token and login\n        import base64\n        username, password = base64.b64decode(token).decode().split(':')\n        \n        subprocess.run([\n            \"docker\", \"login\", \n            \"--username\", username,\n            \"--password\", password,\n            f\"{account}.dkr.ecr.{region}.amazonaws.com\"\n        ], check=True)\n    except Exception as e:\n        print(f\"ECR login failed: {e}\")\n        sys.exit(1)\n    \n    print(\"Tagging and pushing image...\")\n    try:\n        subprocess.run([\"docker\", \"tag\", \"ds-preprocessing\", ecr_uri], check=True)\n        subprocess.run([\"docker\", \"push\", ecr_uri], check=True)\n    except subprocess.CalledProcessError:\n        print(\"Docker push failed\")\n        sys.exit(1)\n    \n    print(f\"Image pushed to {ecr_uri}\")\n    return ecr_uri\n\ndef deploy_infrastructure(environment=\"dev\"):\n    \"\"\"Deploy CDK stack\"\"\"\n    print(f\"Deploying CDK stack for {environment} environment...\")\n    try:\n        subprocess.run([\n            \"cdk\", \"deploy\", \n            \"--app\", \"python infrastructure/app.py\",\n            \"--context\", f\"environment={environment}\",\n            \"--require-approval\", \"never\"\n        ], cwd=\".\", check=True)\n    except subprocess.CalledProcessError:\n        print(\"CDK deployment failed\")\n        sys.exit(1)\n\ndef deploy_cicd():\n    \"\"\"Deploy CI/CD infrastructure\"\"\"\n    print(\"Deploying CI/CD infrastructure...\")\n    try:\n        subprocess.run([\n            \"cdk\", \"deploy\", \n            \"--app\", \"python infrastructure/cicd_app.py\",\n            \"--require-approval\", \"never\"\n        ], cwd=\".\", check=True)\n    except subprocess.CalledProcessError:\n        print(\"CI/CD deployment failed\")\n        sys.exit(1)\n\ndef create_sample_data(environment=\"dev\"):\n    \"\"\"Create and upload sample data for testing\"\"\"\n    account, region = get_account_region()\n    \n    # Create sample input data\n    sample_data = \"\"\"id,value,category\n1,100,A\n2,200,B\n3,150,A\n4,300,C\n5,250,B\"\"\"\n    \n    # Write to temporary file\n    with open('/tmp/sample_data.csv', 'w') as f:\n        f.write(sample_data)\n    \n    # Create dummy model\n    with open('/tmp/model.pkl', 'w') as f:\n        f.write(\"dummy model content for testing\")\n    \n    # Upload to S3\n    s3 = boto3.client('s3')\n    input_bucket = f\"ds-input-{environment}-{account}-{region}\"\n    artifact_bucket = f\"ds-artifacts-{environment}-{account}-{region}\"\n    \n    try:\n        print(f\"Uploading sample data to {input_bucket}...\")\n        s3.upload_file('/tmp/sample_data.csv', input_bucket, 'raw/monthly_data.csv')\n        \n        print(f\"Uploading sample model to {artifact_bucket}...\")\n        s3.upload_file('/tmp/model.pkl', artifact_bucket, 'models/preprocessing_model.pkl')\n        \n        print(\"Sample data uploaded successfully\")\n    except Exception as e:\n        print(f\"Failed to upload sample data: {e}\")\n        print(\"You may need to upload data manually after deployment\")\n\ndef test_pipeline(environment=\"dev\"):\n    \"\"\"Test the deployed pipeline\"\"\"\n    print(f\"Testing {environment} pipeline...\")\n    \n    try:\n        # Get Step Functions ARN\n        sfn = boto3.client('stepfunctions')\n        state_machines = sfn.list_state_machines()\n        \n        pipeline_arn = None\n        for sm in state_machines['stateMachines']:\n            if sm['name'] == 'ds-preprocessing-pipeline':\n                pipeline_arn = sm['stateMachineArn']\n                break\n        \n        if not pipeline_arn:\n            print(\"Pipeline not found. Make sure deployment completed successfully.\")\n            return\n        \n        # Start execution\n        import time\n        execution_name = f\"test-run-{int(time.time())}\"\n        \n        response = sfn.start_execution(\n            stateMachineArn=pipeline_arn,\n            name=execution_name,\n            input='{}'\n        )\n        \n        execution_arn = response['executionArn']\n        print(f\"Started test execution: {execution_arn}\")\n        print(f\"Monitor at: https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/{execution_arn}\")\n        \n    except Exception as e:\n        print(f\"Failed to test pipeline: {e}\")\n\ndef main():\n    parser = argparse.ArgumentParser(description='Deploy DS Pipeline')\n    parser.add_argument('--environment', '-e', choices=['dev', 'prod'], default='dev',\n                       help='Environment to deploy to')\n    parser.add_argument('--skip-image', action='store_true',\n                       help='Skip Docker image build and push')\n    parser.add_argument('--skip-infra', action='store_true', \n                       help='Skip infrastructure deployment')\n    parser.add_argument('--cicd-only', action='store_true',\n                       help='Deploy only CI/CD infrastructure')\n    parser.add_argument('--test', action='store_true',\n                       help='Run pipeline test after deployment')\n    parser.add_argument('--sample-data', action='store_true',\n                       help='Upload sample data for testing')\n    \n    args = parser.parse_args()\n    \n    print(f\"Starting deployment for {args.environment} environment...\")\n    \n    if args.cicd_only:\n        deploy_cicd()\n        print(\"CI/CD deployment complete!\")\n        return\n    \n    # Step 1: Deploy infrastructure (creates ECR repo)\n    if not args.skip_infra:\n        deploy_infrastructure(args.environment)\n    \n    # Step 2: Build and push Docker image\n    if not args.skip_image:\n        build_and_push_image(args.environment)\n    \n    # Step 3: Upload sample data if requested\n    if args.sample_data:\n        create_sample_data(args.environment)\n    \n    # Step 4: Test pipeline if requested\n    if args.test:\n        test_pipeline(args.environment)\n    \n    print(f\"Deployment complete for {args.environment} environment!\")\n    \n    if args.environment == \"prod\":\n        print(\"Production pipeline will run on 15th of every month at 9 AM UTC\")\n    else:\n        print(\"Dev pipeline can be triggered manually for testing\")\n\nif __name__ == \"__main__\":\n    main()